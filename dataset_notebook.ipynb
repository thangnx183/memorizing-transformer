{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17efcb92-f607-4341-9af8-da179b8ad2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34420421-5595-443b-8443-82c2a3305809",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"ccdv/arxiv-summarization\", split='train', streaming=True)\n",
    "raw_dataset = list(dataset.take(3500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9582e3b-ec34-4ac6-91d9-691864cb6b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_size:  5120\n"
     ]
    }
   ],
   "source": [
    "segment = 10           # number of segments\n",
    "segment_length = 512   # context window length\n",
    "chunk_size = segment* segment_length\n",
    "\n",
    "print('chunk_size: ',chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c01fc9-c641-4413-853a-da2f4621c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n",
      "3401\n"
     ]
    }
   ],
   "source": [
    "articles = [d['article'] for d in raw_dataset]\n",
    "print(len(articles))\n",
    "articles = [a for a in articles if len(a) >= chunk_size]\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3710f5b4-ed39-4a1c-a443-dabc5964bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q', 'h', 'r', '(', '?', ';', '.', '-', 'f', 'l', '\\n', '^', '#', '}', '7', '|', 'j', '3', 'k', '6', '*', '%', '8', 'z', '4', '/', '>', '1', '~', '[', 'b', '9', 'c', '!', '\"', 'd', 'e', '{', 't', '+', '0', '&', 'm', ':', ']', '=', 'i', 'n', '5', '`', 'v', 'x', '2', 'g', 'a', 'y', 'u', 'w', \"'\", '$', '_', ',', ')', '@', '<', '\\\\', 's', 'p', 'o', ' '} 70\n"
     ]
    }
   ],
   "source": [
    "unique = set(''.join([i for i in articles]))\n",
    "print(unique, len(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9404cc5-8d58-4280-afa6-22c253236fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(s):\n",
    "    return np.fromstring(s,dtype=np.uint8)\n",
    "\n",
    "def decode_text(s):\n",
    "    return ''.join([chr(i) for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f68170-5a22-4c39-9c75-1767dc02be6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models . \n",
      " it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models . \n",
      " many ex\n",
      "additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models . \n",
      " it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models . \n",
      " many ex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/_bqm2b354mq64jvqy7yhhk200000gn/T/ipykernel_3241/656642625.py:2: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(s,dtype=np.uint8)\n"
     ]
    }
   ],
   "source": [
    "et = encode_text(articles[0][:segment_length])\n",
    "dt = decode_text(et)\n",
    "\n",
    "print(articles[0][:segment_length])\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b246b7-cd5c-42d7-9dfa-cc93bf6f566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/_bqm2b354mq64jvqy7yhhk200000gn/T/ipykernel_3241/656642625.py:2: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(s,dtype=np.uint8)\n"
     ]
    }
   ],
   "source": [
    "def clip_article(article):\n",
    "    remainder = len(article)%chunk_size\n",
    "    return article[:-remainder]\n",
    "\n",
    "# clip all articles into feedable chunk size\n",
    "converted = [encode_text(article) for article in articles]\n",
    "clipped = [clip_article(article) for article in converted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3555be2c-19c7-45b9-967c-b95510acff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20853, 5120])\n"
     ]
    }
   ],
   "source": [
    "chunked = [article.reshape(-1,chunk_size) for article in clipped]\n",
    "processed_data = torch.tensor(np.concatenate(chunked), dtype=torch.long)\n",
    "\n",
    "print(processed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec8f15d2-aecb-42b1-bd08-426e8597291e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipped[0].shape[0]/5120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ecb41d4-8878-40d3-a997-bc49c81e7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(processed_data,batch_size=8,shuffle=True)\n",
    "loader = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e711261-93f8-4468-b478-856b57298e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5119]) torch.Size([8, 5119])\n"
     ]
    }
   ],
   "source": [
    "sample = next(loader)\n",
    "seq = sample[:,:-1]\n",
    "labels = sample[:,1:]\n",
    "\n",
    "print(seq.shape, labels.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c04482d-9ba2-4227-ad7e-f4f205c000d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([101, 100,  32,  ...,  32,  44,  32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e05eb65e-7843-45dd-ba10-e28f53f2d4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100,  32,  97,  ...,  44,  32, 112])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d49f8602-3c0d-413d-91d8-9197ff6c302a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.chunk(10,dim=-1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe1de824-edd9-4242-a5f5-154453105f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7997, grad_fn=<AddBackward0>)\n",
      "tensor(4.6094, grad_fn=<AddBackward0>)\n",
      "tensor(4.2976, grad_fn=<AddBackward0>)\n",
      "tensor(3.9781, grad_fn=<AddBackward0>)\n",
      "tensor(3.7342, grad_fn=<AddBackward0>)\n",
      "tensor(3.4391, grad_fn=<AddBackward0>)\n",
      "tensor(3.3177, grad_fn=<AddBackward0>)\n",
      "tensor(3.2276, grad_fn=<AddBackward0>)\n",
      "tensor(3.1641, grad_fn=<AddBackward0>)\n",
      "tensor(3.3456, grad_fn=<AddBackward0>)\n",
      "tensor(3.2506, grad_fn=<AddBackward0>)\n",
      "tensor(3.1241, grad_fn=<AddBackward0>)\n",
      "tensor(3.0515, grad_fn=<AddBackward0>)\n",
      "tensor(3.1199, grad_fn=<AddBackward0>)\n",
      "tensor(2.9439, grad_fn=<AddBackward0>)\n",
      "tensor(2.9601, grad_fn=<AddBackward0>)\n",
      "tensor(3.2984, grad_fn=<AddBackward0>)\n",
      "tensor(2.9402, grad_fn=<AddBackward0>)\n",
      "tensor(2.9184, grad_fn=<AddBackward0>)\n",
      "tensor(2.8593, grad_fn=<AddBackward0>)\n",
      "tensor(2.8870, grad_fn=<AddBackward0>)\n",
      "tensor(2.8413, grad_fn=<AddBackward0>)\n",
      "tensor(2.8214, grad_fn=<AddBackward0>)\n",
      "tensor(2.8279, grad_fn=<AddBackward0>)\n",
      "tensor(2.8521, grad_fn=<AddBackward0>)\n",
      "tensor(2.7449, grad_fn=<AddBackward0>)\n",
      "tensor(2.7869, grad_fn=<AddBackward0>)\n",
      "tensor(3.0631, grad_fn=<AddBackward0>)\n",
      "tensor(2.7565, grad_fn=<AddBackward0>)\n",
      "tensor(2.7364, grad_fn=<AddBackward0>)\n",
      "tensor(2.9539, grad_fn=<AddBackward0>)\n",
      "tensor(2.7105, grad_fn=<AddBackward0>)\n",
      "tensor(2.7572, grad_fn=<AddBackward0>)\n",
      "tensor(2.7379, grad_fn=<AddBackward0>)\n",
      "tensor(2.6930, grad_fn=<AddBackward0>)\n",
      "tensor(2.7394, grad_fn=<AddBackward0>)\n",
      "tensor(2.6437, grad_fn=<AddBackward0>)\n",
      "tensor(2.7072, grad_fn=<AddBackward0>)\n",
      "tensor(2.6490, grad_fn=<AddBackward0>)\n",
      "tensor(2.7035, grad_fn=<AddBackward0>)\n",
      "tensor(2.7421, grad_fn=<AddBackward0>)\n",
      "tensor(2.8059, grad_fn=<AddBackward0>)\n",
      "tensor(2.6435, grad_fn=<AddBackward0>)\n",
      "tensor(2.6204, grad_fn=<AddBackward0>)\n",
      "tensor(2.9912, grad_fn=<AddBackward0>)\n",
      "tensor(2.6226, grad_fn=<AddBackward0>)\n",
      "tensor(2.7003, grad_fn=<AddBackward0>)\n",
      "tensor(2.7978, grad_fn=<AddBackward0>)\n",
      "tensor(2.6447, grad_fn=<AddBackward0>)\n",
      "tensor(2.7745, grad_fn=<AddBackward0>)\n",
      "tensor(2.6095, grad_fn=<AddBackward0>)\n",
      "tensor(2.5262, grad_fn=<AddBackward0>)\n",
      "tensor(2.7766, grad_fn=<AddBackward0>)\n",
      "tensor(2.6928, grad_fn=<AddBackward0>)\n",
      "tensor(2.6334, grad_fn=<AddBackward0>)\n",
      "tensor(2.5940, grad_fn=<AddBackward0>)\n",
      "tensor(2.7721, grad_fn=<AddBackward0>)\n",
      "tensor(2.6186, grad_fn=<AddBackward0>)\n",
      "tensor(2.6285, grad_fn=<AddBackward0>)\n",
      "tensor(2.8912, grad_fn=<AddBackward0>)\n",
      "tensor(2.6325, grad_fn=<AddBackward0>)\n",
      "tensor(2.7220, grad_fn=<AddBackward0>)\n",
      "tensor(2.5303, grad_fn=<AddBackward0>)\n",
      "tensor(2.6046, grad_fn=<AddBackward0>)\n",
      "tensor(2.6268, grad_fn=<AddBackward0>)\n",
      "tensor(2.5993, grad_fn=<AddBackward0>)\n",
      "tensor(2.5935, grad_fn=<AddBackward0>)\n",
      "tensor(2.5759, grad_fn=<AddBackward0>)\n",
      "tensor(2.5387, grad_fn=<AddBackward0>)\n",
      "tensor(2.8665, grad_fn=<AddBackward0>)\n",
      "tensor(2.5548, grad_fn=<AddBackward0>)\n",
      "tensor(2.5568, grad_fn=<AddBackward0>)\n",
      "tensor(2.5540, grad_fn=<AddBackward0>)\n",
      "tensor(2.4730, grad_fn=<AddBackward0>)\n",
      "tensor(2.5487, grad_fn=<AddBackward0>)\n",
      "tensor(2.5288, grad_fn=<AddBackward0>)\n",
      "tensor(2.6774, grad_fn=<AddBackward0>)\n",
      "tensor(2.5278, grad_fn=<AddBackward0>)\n",
      "tensor(2.7931, grad_fn=<AddBackward0>)\n",
      "tensor(2.5326, grad_fn=<AddBackward0>)\n",
      "tensor(2.5559, grad_fn=<AddBackward0>)\n",
      "tensor(2.5120, grad_fn=<AddBackward0>)\n",
      "tensor(2.6375, grad_fn=<AddBackward0>)\n",
      "tensor(2.5684, grad_fn=<AddBackward0>)\n",
      "tensor(2.5892, grad_fn=<AddBackward0>)\n",
      "tensor(2.6129, grad_fn=<AddBackward0>)\n",
      "tensor(2.4608, grad_fn=<AddBackward0>)\n",
      "tensor(2.5494, grad_fn=<AddBackward0>)\n",
      "tensor(2.5279, grad_fn=<AddBackward0>)\n",
      "tensor(2.5716, grad_fn=<AddBackward0>)\n",
      "tensor(2.5606, grad_fn=<AddBackward0>)\n",
      "tensor(2.5563, grad_fn=<AddBackward0>)\n",
      "tensor(2.5315, grad_fn=<AddBackward0>)\n",
      "tensor(2.7148, grad_fn=<AddBackward0>)\n",
      "tensor(2.5904, grad_fn=<AddBackward0>)\n",
      "tensor(2.6783, grad_fn=<AddBackward0>)\n",
      "tensor(2.7253, grad_fn=<AddBackward0>)\n",
      "tensor(2.5374, grad_fn=<AddBackward0>)\n",
      "tensor(2.5131, grad_fn=<AddBackward0>)\n",
      "tensor(2.5623, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Embedding(128,16),\n",
    "    nn.Linear(16,150),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(150,150),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(150,128)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.05)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    chunk = next(loader)\n",
    "    seq = chunk[:,:-1]\n",
    "    labels = chunk[:,1:]\n",
    "\n",
    "    train_loss = 0\n",
    "    for seq_segment, labels_segment in zip(seq.chunk(segment,dim=-1), labels.chunk(segment, dim=-1)):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(seq_segment)\n",
    "        #print(y_pred.shape)\n",
    "        #print(labels_segment.shape)\n",
    "        loss = loss_fn(y_pred.transpose(2,1),labels_segment)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss / segment\n",
    "        #print(loss)\n",
    "        #break\n",
    "    #break\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9457b8-8168-4b30-9202-89860e638bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem-trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
